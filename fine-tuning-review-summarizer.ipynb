{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\n!pip install -qU unsloth transformers datasets bitsandbytes seaborn pandas wandb huggingface_hub","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-02-02T08:45:21.790021Z","iopub.execute_input":"2026-02-02T08:45:21.790597Z","iopub.status.idle":"2026-02-02T08:48:31.844912Z","shell.execute_reply.started":"2026-02-02T08:45:21.790563Z","shell.execute_reply":"2026-02-02T08:48:31.843707Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import torch\ntorch.__version__","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T08:48:35.772876Z","iopub.execute_input":"2026-02-02T08:48:35.773522Z","iopub.status.idle":"2026-02-02T08:48:38.211916Z","shell.execute_reply.started":"2026-02-02T08:48:35.773484Z","shell.execute_reply":"2026-02-02T08:48:38.211083Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"'2.10.0+cu128'"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"import os\nimport wandb\nfrom datetime import datetime\nfrom kaggle_secrets import UserSecretsClient\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nuser_secrets = UserSecretsClient()\nwb_token = user_secrets.get_secret(\"wandb\")\n\nwandb.finish() # End any zombie sessions\nwandb.login(key=wb_token)\n\nproject_name = \"Fine-tune Llama-3 on ABSA and Review Summary\"\nrun_name = f\"llama3-run-{datetime.now().strftime('%H-%M-%S')}\"\nwandb.init(project=project_name, name=run_name, anonymous=\"allow\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T08:48:45.003077Z","iopub.execute_input":"2026-02-02T08:48:45.003987Z","iopub.status.idle":"2026-02-02T08:49:01.815052Z","shell.execute_reply.started":"2026-02-02T08:48:45.003955Z","shell.execute_reply":"2026-02-02T08:49:01.814460Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: [wandb.login()] Using explicit session credentials for https://api.wandb.ai.\n\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbadhan45457\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The anonymous setting has no effect and will be removed in a future version.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.24.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20260202_084854-t9pnslb3</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/badhan45457/Fine-tune%20Llama-3%20on%20ABSA%20and%20Review%20Summary/runs/t9pnslb3' target=\"_blank\">llama3-run-08-48-53</a></strong> to <a href='https://wandb.ai/badhan45457/Fine-tune%20Llama-3%20on%20ABSA%20and%20Review%20Summary' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/badhan45457/Fine-tune%20Llama-3%20on%20ABSA%20and%20Review%20Summary' target=\"_blank\">https://wandb.ai/badhan45457/Fine-tune%20Llama-3%20on%20ABSA%20and%20Review%20Summary</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/badhan45457/Fine-tune%20Llama-3%20on%20ABSA%20and%20Review%20Summary/runs/t9pnslb3' target=\"_blank\">https://wandb.ai/badhan45457/Fine-tune%20Llama-3%20on%20ABSA%20and%20Review%20Summary/runs/t9pnslb3</a>"},"metadata":{}},{"execution_count":3,"output_type":"execute_result","data":{"text/html":"<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/badhan45457/Fine-tune%20Llama-3%20on%20ABSA%20and%20Review%20Summary/runs/t9pnslb3?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>","text/plain":"<wandb.sdk.wandb_run.Run at 0x78d3e98996d0>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"import torch\nfrom trl import SFTTrainer, SFTConfig\nfrom unsloth import FastLanguageModel\nfrom unsloth import is_bfloat16_supported\n\nmax_seq_length = 2048\ndtype = None\nload_in_4bit = True\n\n# load the pre-trained model\nmodel, tokenizer = FastLanguageModel.from_pretrained(\n    model_name = \"unsloth/llama-3-8b-bnb-4bit\",\n    max_seq_length = max_seq_length,\n    dtype = dtype,\n    load_in_4bit = load_in_4bit,\n)\n\ntokenizer.pad_token_id = tokenizer.eos_token_id\n\n# Set base model to inference mode \nFastLanguageModel.for_inference(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T08:49:07.782825Z","iopub.execute_input":"2026-02-02T08:49:07.783103Z","iopub.status.idle":"2026-02-02T08:50:11.440319Z","shell.execute_reply.started":"2026-02-02T08:49:07.783080Z","shell.execute_reply":"2026-02-02T08:50:11.439434Z"}},"outputs":[{"name":"stderr","text":"2026-02-02 08:49:14.600454: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1770022154.797830      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1770022154.854022      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1770022155.335052      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1770022155.335092      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1770022155.335095      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1770022155.335098      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nSkipping import of cpp extensions due to incompatible torch version 2.10.0+cu128 for torchao version 0.15.0             Please see https://github.com/pytorch/ao/issues/2919 for more info\n","output_type":"stream"},{"name":"stdout","text":"ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\nðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n==((====))==  Unsloth 2026.1.4: Fast Llama patching. Transformers: 4.57.6.\n   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.563 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.10.0+cu128. CUDA: 7.5. CUDA Toolkit: 12.8. Triton: 3.6.0\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.34. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/5.70G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"309414ae4e7b4e998e970c17d570e169"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/198 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c3d666746ac4bb7bdddcbc981b91129"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3058125c1acf470f8ebcb2b31f543cce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a05972e63474779a68540a3b432d0d2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2955d813936647cf8238cba355ce353f"}},"metadata":{}},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"LlamaForCausalLM(\n  (model): LlamaModel(\n    (embed_tokens): Embedding(128256, 4096, padding_idx=128255)\n    (layers): ModuleList(\n      (0-31): 32 x LlamaDecoderLayer(\n        (self_attn): LlamaAttention(\n          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n          (rotary_emb): LlamaRotaryEmbedding()\n        )\n        (mlp): LlamaMLP(\n          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n          (act_fn): SiLUActivation()\n        )\n        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n      )\n    )\n    (norm): LlamaRMSNorm((4096,), eps=1e-05)\n    (rotary_emb): LlamaRotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n)"},"metadata":{}}],"execution_count":4},{"cell_type":"markdown","source":"## Generation with Base Model","metadata":{}},{"cell_type":"code","source":"from transformers import TextStreamer\n\ntest_review = \"The pasta was absolutely delicious, easily the best I've had in the city. However, we waited 45 minutes for our table despite having a reservation. The noise level was also a bit too high for conversation.\"\n\ninputs = tokenizer([test_review], return_tensors = \"pt\").to(model.device)\n\nstreamer = TextStreamer(tokenizer, skip_prompt=True)\n\n_ = model.generate(\n    **inputs, \n    streamer = streamer,\n    max_new_tokens = 40,\n    use_cache = True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T08:50:15.406779Z","iopub.execute_input":"2026-02-02T08:50:15.407634Z","iopub.status.idle":"2026-02-02T08:50:23.756543Z","shell.execute_reply.started":"2026-02-02T08:50:15.407599Z","shell.execute_reply":"2026-02-02T08:50:23.755906Z"}},"outputs":[{"name":"stdout","text":" But overall, I would definitely go back.\nThe food was delicious. The service was attentive and friendly. I would definitely recommend this place.\nThe food was very good, but the service was a bit\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"## Finetuning Start","metadata":{}},{"cell_type":"code","source":"# Switch back to training mode\nFastLanguageModel.for_training(model)\n\n# 3. Attach LoRA Adapters\nlayers_to_tune = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"]\n\nmodel = FastLanguageModel.get_peft_model(\n    model,\n    r = 16, \n    target_modules = layers_to_tune,\n    lora_alpha = 16,\n    lora_dropout = 0,\n    bias = \"none\",\n    use_gradient_checkpointing = \"unsloth\",\n    random_state = 3407,\n    use_rslora = False, \n    loftq_config = None\n)\n\nprint(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T08:50:31.786947Z","iopub.execute_input":"2026-02-02T08:50:31.787611Z","iopub.status.idle":"2026-02-02T08:50:38.990544Z","shell.execute_reply.started":"2026-02-02T08:50:31.787566Z","shell.execute_reply":"2026-02-02T08:50:38.989592Z"}},"outputs":[{"name":"stderr","text":"Unsloth 2026.1.4 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n","output_type":"stream"},{"name":"stdout","text":"PeftModelForCausalLM(\n  (base_model): LoraModel(\n    (model): LlamaForCausalLM(\n      (model): LlamaModel(\n        (embed_tokens): Embedding(128256, 4096, padding_idx=128255)\n        (layers): ModuleList(\n          (0-31): 32 x LlamaDecoderLayer(\n            (self_attn): LlamaAttention(\n              (q_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Identity()\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (k_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Identity()\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=1024, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (v_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Identity()\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=1024, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (o_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Identity()\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (rotary_emb): LlamaRotaryEmbedding()\n            )\n            (mlp): LlamaMLP(\n              (gate_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Identity()\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=14336, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (up_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Identity()\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=14336, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (down_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Identity()\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=14336, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (act_fn): SiLUActivation()\n            )\n            (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n            (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n          )\n        )\n        (norm): LlamaRMSNorm((4096,), eps=1e-05)\n        (rotary_emb): LlamaRotaryEmbedding()\n      )\n      (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n    )\n  )\n)\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# TEMPLATE: Optimized for Llama 3 Restaurant ABSA\nalpaca_prompt_train = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n\n## Instruction:\nYou are an expert restaurant critic and sentiment analyst. Your task is to analyze the customer review provided below and extract structured insights.\n\nFollow these specific steps:\n1. **Aspect Analysis**: Analyze the text to determine the sentiment for specific categories. You must classify each category as 'Positive', 'Negative', or 'Neutral'.\n   - **Ambiance**: Decor, atmosphere, noise level, lighting.\n   - **Cleanliness**: Hygiene, tidiness of the space.\n   - **Food**: Taste, temperature, portion size, menu variety.\n   - **Service**: Staff behavior, speed, attentiveness.\n   - **Value**: Price appropriateness, worth the money.\n   \n   If a category is not explicitly mentioned but can be strongly inferred, classify it. If absolutely no info is present, use 'Neutral'.\n\n2. **Summarization**: Write a concise, one-sentence summary of the review that captures the main pros and cons.\n\n## Input:\n{review}\n\n## Response:\n### Aspect Sentiments:\n{formatted_sentiment}\n\n### Summary:\n{summary}\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T08:50:50.468825Z","iopub.execute_input":"2026-02-02T08:50:50.469184Z","iopub.status.idle":"2026-02-02T08:50:50.475762Z","shell.execute_reply.started":"2026-02-02T08:50:50.469152Z","shell.execute_reply":"2026-02-02T08:50:50.475095Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"from datasets import load_dataset, DatasetDict\n\nreview_dataset = \"navdeep-singh/sentiment-aware-review-summarization\"\n\ntrain_dataset = load_dataset(review_dataset, split = \"train\")\neval_dataset = load_dataset(review_dataset, split = \"test\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T08:50:52.594289Z","iopub.execute_input":"2026-02-02T08:50:52.595166Z","iopub.status.idle":"2026-02-02T08:50:56.318843Z","shell.execute_reply.started":"2026-02-02T08:50:52.595132Z","shell.execute_reply":"2026-02-02T08:50:56.317930Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/731 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8fc4724a443b4a5a99fb143c22df33a8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/train-00000-of-00001.parquet:   0%|          | 0.00/391k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41d843bb242345838153b7cf43483e15"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/test-00000-of-00001.parquet:   0%|          | 0.00/52.2k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"efad94bd9d41455c988a364af8332586"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/896 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23262e2d7ca94ea096f2c874c3aa46b7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21dfd40295d24d078907be7618dd7c5d"}},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"def format_data_point(row):\n    # 1. Convert the sentiment dict into a clean, readable list\n    # Input: {'Ambiance': 'Positive', 'Food': 'Positive', ...}\n    # Output: \"Ambiance: Positive\\nCleanliness: Positive...\"\n    sentiment_dict = row['sentiment']\n    formatted_sentiment = \"\\n\".join([f\"- {k}: {v}\" for k, v in sentiment_dict.items()])\n    \n    # 2. Fill the prompt\n    # Note: We map your data keys ('review', 'summary') to the prompt slots\n    text = alpaca_prompt_train.format(\n        review=row['review'],\n        formatted_sentiment=formatted_sentiment,\n        summary=row['summary']\n    )    \n    return {\"text\": text}\n\n# (Use batched=False as discussed previously)\ntrain_dataset = train_dataset.map(format_data_point, batched=False)\neval_dataset = eval_dataset.map(format_data_point, batched=False)\n\nprint(f\"Train Size: {len(train_dataset)}\")\nprint(f\"Validation Size: {len(eval_dataset)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T08:51:03.134134Z","iopub.execute_input":"2026-02-02T08:51:03.134735Z","iopub.status.idle":"2026-02-02T08:51:03.278506Z","shell.execute_reply.started":"2026-02-02T08:51:03.134698Z","shell.execute_reply":"2026-02-02T08:51:03.277685Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/896 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"61f070c77bd74394b2adae72955955b8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"51a1620b3fd1458f81a8753a7f643db7"}},"metadata":{}},{"name":"stdout","text":"Train Size: 896\nValidation Size: 100\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"from trl import SFTTrainer, SFTConfig\n\n# Set to RIGHT for SFTTrainer\ntokenizer.padding_side = \"right\"   \n\n# 1. Configure SFTConfig \nsft_config = SFTConfig(\n    dataset_text_field=\"text\",\n    \n    # Standard args\n    per_device_train_batch_size=4,\n    gradient_accumulation_steps=8,\n    \n    warmup_steps=10,\n    max_steps=50,\n    learning_rate=2e-4,\n\n    fp16 = not is_bfloat16_supported(),\n    bf16 = is_bfloat16_supported(),\n\n    output_dir = \"outputs\",\n\n    logging_strategy = \"steps\",\n    logging_steps = 1,\n    \n    eval_strategy = \"steps\",              # Check validation loss every X steps\n    eval_steps = 5,                       # Calculate val loss every 5 steps\n    \n    save_strategy = \"steps\",              # Save model checkpoint every X steps\n    save_steps = 5,                       # Match this with eval_steps usually\n    \n    load_best_model_at_end = True,\n)\n\n# 2. Initialize Trainer\ntrainer = SFTTrainer(\n    model=model,\n    processing_class=tokenizer, \n\n    train_dataset=train_dataset,\n    eval_dataset=eval_dataset,\n    \n    max_seq_length=2048, \n    \n    args=sft_config\n)\n\ntrainer_stats = trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T08:51:14.071168Z","iopub.execute_input":"2026-02-02T08:51:14.072013Z","iopub.status.idle":"2026-02-02T09:40:41.172076Z","shell.execute_reply.started":"2026-02-02T08:51:14.071975Z","shell.execute_reply":"2026-02-02T09:40:41.171269Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Unsloth: Tokenizing [\"text\"] (num_proc=8):   0%|          | 0/896 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b788bffce9141c385abe5a0f2ee299f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Unsloth: Tokenizing [\"text\"] (num_proc=8):   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f16824805a4444fb22a6418b243cbc2"}},"metadata":{}},{"name":"stderr","text":"The model is already on multiple devices. Skipping the move to device specified in `args`.\n","output_type":"stream"},{"name":"stdout","text":"ðŸ¦¥ Unsloth: Padding-free auto-enabled, enabling faster training.\n","output_type":"stream"},{"name":"stderr","text":"==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n   \\\\   /|    Num examples = 896 | Num Epochs = 2 | Total steps = 50\nO^O/ \\_/ \\    Batch size per device = 4 | Gradient accumulation steps = 8\n\\        /    Data Parallel GPUs = 1 | Total batch size (4 x 8 x 1) = 32\n \"-____-\"     Trainable parameters = 41,943,040 of 8,072,204,288 (0.52% trained)\n","output_type":"stream"},{"name":"stdout","text":"Unsloth: Will smartly offload gradients to save VRAM!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [50/50 48:26, Epoch 1/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>5</td>\n      <td>1.550900</td>\n      <td>1.455728</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.856400</td>\n      <td>0.731473</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>0.452000</td>\n      <td>0.448789</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>0.407100</td>\n      <td>0.405463</td>\n    </tr>\n    <tr>\n      <td>25</td>\n      <td>0.390500</td>\n      <td>0.377889</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>0.339200</td>\n      <td>0.356622</td>\n    </tr>\n    <tr>\n      <td>35</td>\n      <td>0.332000</td>\n      <td>0.342693</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>0.314400</td>\n      <td>0.329905</td>\n    </tr>\n    <tr>\n      <td>45</td>\n      <td>0.311200</td>\n      <td>0.322903</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>0.320400</td>\n      <td>0.320539</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Unsloth: Not an error, but LlamaForCausalLM does not accept `num_items_in_batch`.\nUsing gradient accumulation will be very slightly less accurate.\nRead more on gradient accumulation issues here: https://unsloth.ai/blog/gradient\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">llama3-run-08-48-53</strong> at: <a href='https://wandb.ai/badhan45457/Fine-tune%20Llama-3%20on%20ABSA%20and%20Review%20Summary/runs/t9pnslb3' target=\"_blank\">https://wandb.ai/badhan45457/Fine-tune%20Llama-3%20on%20ABSA%20and%20Review%20Summary/runs/t9pnslb3</a><br> View project at: <a href='https://wandb.ai/badhan45457/Fine-tune%20Llama-3%20on%20ABSA%20and%20Review%20Summary' target=\"_blank\">https://wandb.ai/badhan45457/Fine-tune%20Llama-3%20on%20ABSA%20and%20Review%20Summary</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20260202_084854-t9pnslb3/logs</code>"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"alpaca_prompt_inference = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n\n### Instruction:\nYou are an expert restaurant critic and sentiment analyst. Your task is to analyze the customer review provided below and extract structured insights.\n\nFollow these specific steps:\n1. **Aspect Analysis**: Analyze the text to determine the sentiment for specific categories. You must classify each category as 'Positive', 'Negative', or 'Neutral'.\n   - **Ambiance**: Decor, atmosphere, noise level, lighting.\n   - **Cleanliness**: Hygiene, tidiness of the space.\n   - **Food**: Taste, temperature, portion size, menu variety.\n   - **Service**: Staff behavior, speed, attentiveness.\n   - **Value**: Price appropriateness, worth the money.\n   \n   If a category is not explicitly mentioned but can be strongly inferred, classify it. If absolutely no info is present, use 'Neutral'.\n\n2. **Summarization**: Write a concise, one-sentence summary of the review that captures the main pros and cons.\n\n### Input:\n{review}\n\n### Response:\n\"\"\"\n\ntokenizer.padding_side = \"left\"   # Switch to LEFT for Generation\nFastLanguageModel.for_inference(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T09:43:44.738667Z","iopub.execute_input":"2026-02-02T09:43:44.739398Z","iopub.status.idle":"2026-02-02T09:43:44.769101Z","shell.execute_reply.started":"2026-02-02T09:43:44.739361Z","shell.execute_reply":"2026-02-02T09:43:44.768462Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"PeftModelForCausalLM(\n  (base_model): LoraModel(\n    (model): LlamaForCausalLM(\n      (model): LlamaModel(\n        (embed_tokens): Embedding(128256, 4096, padding_idx=128255)\n        (layers): ModuleList(\n          (0-31): 32 x LlamaDecoderLayer(\n            (self_attn): LlamaAttention(\n              (q_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Identity()\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (k_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Identity()\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=1024, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (v_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Identity()\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=1024, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (o_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Identity()\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (rotary_emb): LlamaRotaryEmbedding()\n            )\n            (mlp): LlamaMLP(\n              (gate_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Identity()\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=14336, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (up_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Identity()\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=14336, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (down_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Identity()\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=14336, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (act_fn): SiLUActivation()\n            )\n            (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n            (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n          )\n        )\n        (norm): LlamaRMSNorm((4096,), eps=1e-05)\n        (rotary_emb): LlamaRotaryEmbedding()\n      )\n      (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n    )\n  )\n)"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"test_review = \"The pasta was absolutely delicious, easily the best I've had in the city. However, we waited 45 minutes for our table despite having a reservation. The noise level was also a bit too high for conversation.\"\n\n\ninputs = tokenizer([alpaca_prompt_inference.format(review=test_review)], return_tensors = \"pt\").to(\"cuda\")\n\n# 5. Generate Output\noutputs = model.generate(\n    **inputs, \n    max_new_tokens = 128,  # Limit output length\n    use_cache = True,\n    temperature = 0.1,     # Low temp = more factual/stable answers\n)\n\n# 6. Decode and Print\n# We slice [inputs.input_ids.shape[1]:] to remove the prompt from the output\nprediction = tokenizer.batch_decode(outputs[:, inputs['input_ids'].shape[1]:], skip_special_tokens=True)[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T09:43:48.501703Z","iopub.execute_input":"2026-02-02T09:43:48.502246Z","iopub.status.idle":"2026-02-02T09:43:53.420063Z","shell.execute_reply.started":"2026-02-02T09:43:48.502213Z","shell.execute_reply":"2026-02-02T09:43:53.419454Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"print(\"PREDICTION:\\n\")\nprint(prediction)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T09:43:53.421650Z","iopub.execute_input":"2026-02-02T09:43:53.422026Z","iopub.status.idle":"2026-02-02T09:43:53.426975Z","shell.execute_reply.started":"2026-02-02T09:43:53.421997Z","shell.execute_reply":"2026-02-02T09:43:53.426302Z"}},"outputs":[{"name":"stdout","text":"PREDICTION:\n\n#### Aspect Sentiments:\n- Ambiance: Negative\n- Cleanliness: Positive\n- Food: Positive\n- Service: Negative\n- Value: Neutral\n\n#### Summary:\nGreat food, but terrible service and noise. Worth a visit for the pasta, but maybe not for a special occasion.\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"## Save the adapter locally","metadata":{}},{"cell_type":"code","source":"adapter = \"ABSA-Summarizer-LoRA\"\n\nmodel.save_pretrained(adapter)\ntokenizer.save_pretrained(adapter)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T09:44:00.033304Z","iopub.execute_input":"2026-02-02T09:44:00.033659Z","iopub.status.idle":"2026-02-02T09:44:00.721002Z","shell.execute_reply.started":"2026-02-02T09:44:00.033629Z","shell.execute_reply":"2026-02-02T09:44:00.720400Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"('ABSA-Summarizer-LoRA/tokenizer_config.json',\n 'ABSA-Summarizer-LoRA/special_tokens_map.json',\n 'ABSA-Summarizer-LoRA/tokenizer.json')"},"metadata":{}}],"execution_count":14},{"cell_type":"markdown","source":"## Push the adapter to huggingface\n\nThe adapter config file itself contains basse model info, so during loading of adapter it automatically load base model also, if base mode doesn't exist in storage","metadata":{}},{"cell_type":"code","source":"from huggingface_hub import login\n\nhf_token = user_secrets.get_secret(\"HF_TOKEN\")\n\ntry:\n    login(token=hf_token)\n    print(\"Successfully logged in to Hugging Face!\")\nexcept Exception as e:\n    print(f\"Login failed: {e}\")\n    exit()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T09:47:02.693465Z","iopub.execute_input":"2026-02-02T09:47:02.693835Z","iopub.status.idle":"2026-02-02T09:47:02.775678Z","shell.execute_reply.started":"2026-02-02T09:47:02.693805Z","shell.execute_reply":"2026-02-02T09:47:02.774915Z"}},"outputs":[{"name":"stdout","text":"Successfully logged in to Hugging Face!\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"adapter_name = f\"Llama-3-8b-{adapter}\"\nusername = \"navdeep-singh\"\n\nREPO_NAME = f\"{username}/{adapter_name}\"\n\n# 3. Push to Hub\ntry:\n    print(f\"Pushing adapter to: {REPO_NAME}...\")\n    # 2. Push with that name\n    model.push_to_hub(REPO_NAME)\n    tokenizer.push_to_hub(REPO_NAME)\n    print(f\"âœ… Successfully published! View it here: https://huggingface.co/{REPO_NAME}\")\nexcept Exception as e:\n    print(f\"Error pushing to Hub: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T09:47:05.201215Z","iopub.execute_input":"2026-02-02T09:47:05.201579Z","iopub.status.idle":"2026-02-02T09:47:10.709684Z","shell.execute_reply.started":"2026-02-02T09:47:05.201548Z","shell.execute_reply":"2026-02-02T09:47:10.708908Z"}},"outputs":[{"name":"stdout","text":"Pushing adapter to: navdeep-singh/Llama-3-8b-ABSA-Summarizer-LoRA...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Processing Files (0 / 0): |          |  0.00B /  0.00B            ","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c8787285f96e4d82801b01fc8bb58f5f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"New Data Upload: |          |  0.00B /  0.00B            ","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35dba03968d143e3ac3d8c840933dc35"}},"metadata":{}},{"name":"stdout","text":"Saved model to https://huggingface.co/navdeep-singh/Llama-3-8b-ABSA-Summarizer-LoRA\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Processing Files (0 / 0): |          |  0.00B /  0.00B            ","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ff37f58752d45e68c9615ed93fdfc7c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"New Data Upload: |          |  0.00B /  0.00B            ","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b41cbb8263e648feb6d3dbed15e25e9d"}},"metadata":{}},{"name":"stdout","text":"âœ… Successfully published! View it here: https://huggingface.co/navdeep-singh/Llama-3-8b-ABSA-Summarizer-LoRA\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"### Model Testing by Loading from Huggingface!","metadata":{}},{"cell_type":"code","source":"\nmodel, tokenizer = FastLanguageModel.from_pretrained(\n    model_name = \"navdeep-singh/Llama-3-8b-ABSA-Summarizer-LoRA\",\n    max_seq_length = max_seq_length,\n    dtype = dtype,\n    load_in_4bit = load_in_4bit,\n)\n\ntokenizer.pad_token_id = tokenizer.eos_token_id\n\n# Set base model to inference mode \nFastLanguageModel.for_inference(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T10:16:19.263643Z","iopub.execute_input":"2026-02-02T10:16:19.264333Z","iopub.status.idle":"2026-02-02T10:16:43.297659Z","shell.execute_reply.started":"2026-02-02T10:16:19.264301Z","shell.execute_reply":"2026-02-02T10:16:43.296710Z"}},"outputs":[{"name":"stdout","text":"==((====))==  Unsloth 2026.1.4: Fast Llama patching. Transformers: 4.57.6.\n   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.563 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.10.0+cu128. CUDA: 7.5. CUDA Toolkit: 12.8. Triton: 3.6.0\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.34. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/168M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dac1def5c41d48ddb3e697a56a348519"}},"metadata":{}},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"PeftModelForCausalLM(\n  (base_model): LoraModel(\n    (model): LlamaForCausalLM(\n      (model): LlamaModel(\n        (embed_tokens): Embedding(128256, 4096, padding_idx=128255)\n        (layers): ModuleList(\n          (0-31): 32 x LlamaDecoderLayer(\n            (self_attn): LlamaAttention(\n              (q_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Identity()\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (k_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Identity()\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=1024, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (v_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Identity()\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=1024, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (o_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Identity()\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (rotary_emb): LlamaRotaryEmbedding()\n            )\n            (mlp): LlamaMLP(\n              (gate_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Identity()\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=14336, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (up_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Identity()\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=14336, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (down_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Identity()\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=14336, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (act_fn): SiLUActivation()\n            )\n            (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n            (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n          )\n        )\n        (norm): LlamaRMSNorm((4096,), eps=1e-05)\n        (rotary_emb): LlamaRotaryEmbedding()\n      )\n      (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n    )\n  )\n)"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"test_review = \"The steak was cooked to perfection, honestly some of the most flavorful meat I've ever tasted. That said, the service was incredibly slow; we sat for nearly half an hour before a server even took our drink order. It was also freezing inside, which made it hard to fully relax and enjoy the meal.\"\n\n\ninputs = tokenizer([alpaca_prompt_inference.format(review=test_review)], return_tensors = \"pt\").to(\"cuda\")\n\n# 5. Generate Output\noutputs = model.generate(\n    **inputs, \n    max_new_tokens = 128,  # Limit output length\n    use_cache = True,\n    temperature = 0.1,     # Low temp = more factual/stable answers\n)\n\n# 6. Decode and Print\n# We slice [inputs.input_ids.shape[1]:] to remove the prompt from the output\nprediction = tokenizer.batch_decode(outputs[:, inputs['input_ids'].shape[1]:], skip_special_tokens=True)[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T10:17:46.511537Z","iopub.execute_input":"2026-02-02T10:17:46.511911Z","iopub.status.idle":"2026-02-02T10:17:50.355829Z","shell.execute_reply.started":"2026-02-02T10:17:46.511869Z","shell.execute_reply":"2026-02-02T10:17:50.355208Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"print(\"PREDICTION:\\n\")\nprint(prediction)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T10:17:53.391217Z","iopub.execute_input":"2026-02-02T10:17:53.391627Z","iopub.status.idle":"2026-02-02T10:17:53.396029Z","shell.execute_reply.started":"2026-02-02T10:17:53.391584Z","shell.execute_reply":"2026-02-02T10:17:53.395382Z"}},"outputs":[{"name":"stdout","text":"PREDICTION:\n\n#### Aspect Sentiments:\n- Ambiance: Negative\n- Cleanliness: Neutral\n- Food: Positive\n- Service: Negative\n- Value: Neutral\n\n#### Summary:\nGreat food, but terrible service and uncomfortable temperature.\n","output_type":"stream"}],"execution_count":26}]}